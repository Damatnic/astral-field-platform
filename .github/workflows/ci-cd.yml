name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  NODE_VERSION: '18.x'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Code Quality and Linting
  code-quality:
    runs-on: ubuntu-latest
    name: Code Quality & Linting
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run ESLint
      run: npm run lint
      
    - name: Run TypeScript check
      run: npm run type-check
      
    - name: Check code formatting
      run: npx prettier --check .
      
    - name: Security audit
      run: npm audit --audit-level=moderate
      continue-on-error: true

  # Unit and Integration Tests
  test:
    runs-on: ubuntu-latest
    name: Unit & Integration Tests
    needs: code-quality
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: astral_field_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Setup test environment
      run: |
        cp .env.example .env.test
        echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/astral_field_test" >> .env.test
        echo "REDIS_URL=redis://localhost:6379" >> .env.test
        
    - name: Run database migrations
      run: npm run db:migrate
      env:
        NODE_ENV: test
        
    - name: Run unit tests
      run: npm run test -- --coverage --watchAll=false
      env:
        NODE_ENV: test
        
    - name: Run integration tests
      run: npm run test:integration
      env:
        NODE_ENV: test
        
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # End-to-End Tests
  e2e-tests:
    runs-on: ubuntu-latest
    name: End-to-End Tests
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Install Playwright browsers
      run: npx playwright install --with-deps
      
    - name: Build application
      run: npm run build
      env:
        NODE_ENV: test
        
    - name: Start application
      run: npm start &
      env:
        NODE_ENV: test
        PORT: 3000
        
    - name: Wait for application
      run: npx wait-on http://localhost:3000
      
    - name: Run E2E tests
      run: npm run test:e2e
      env:
        PLAYWRIGHT_BASE_URL: http://localhost:3000
        
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: e2e-test-results
        path: |
          test-results/
          playwright-report/
        retention-days: 5

  # Performance Tests
  performance-tests:
    runs-on: ubuntu-latest
    name: Performance Tests
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build application
      run: npm run build
      
    - name: Start application
      run: npm start &
      env:
        NODE_ENV: production
        PORT: 3000
        
    - name: Wait for application
      run: npx wait-on http://localhost:3000
      
    - name: Install k6
      run: |
        sudo gpg -k
        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
        
    - name: Run performance tests
      run: k6 run performance-tests/load-test.js
      env:
        BASE_URL: http://localhost:3000
        
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      with:
        name: performance-test-results
        path: |
          performance-report.json
          performance-report.html
        retention-days: 30

  # Security Scanning
  security:
    runs-on: ubuntu-latest
    name: Security Scanning
    needs: code-quality
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
        
    - name: Run Snyk to check for vulnerabilities
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=high
      continue-on-error: true

  # Build and Push Docker Image
  build-image:
    runs-on: ubuntu-latest
    name: Build Docker Image
    needs: [test, e2e-tests]
    if: github.event_name == 'push'
    
    permissions:
      contents: read
      packages: write
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix=sha-
          type=raw,value=latest,enable={{is_default_branch}}
          
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Generate SBOM
      uses: anchore/sbom-action@v0
      with:
        image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
        format: spdx-json
        output-file: sbom.spdx.json
        
    - name: Upload SBOM
      uses: actions/upload-artifact@v3
      with:
        name: sbom
        path: sbom.spdx.json

  # Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    name: Deploy to Staging
    needs: [build-image, security]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add deployment commands here (e.g., kubectl, helm, etc.)
        
    - name: Run smoke tests
      run: |
        echo "Running smoke tests against staging..."
        # Add smoke test commands here
        
    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: 'Staging deployment completed successfully! ðŸš€'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    name: Deploy to Production
    needs: [build-image, security]
    if: github.ref == 'refs/heads/main' && (github.event_name == 'push' || github.event.inputs.environment == 'production')
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Deploy to production
      run: |
        echo "Deploying to production environment..."
        # Add production deployment commands here
        
    - name: Run post-deployment tests
      run: |
        echo "Running post-deployment verification..."
        # Add verification commands here
        
    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: 'Production deployment completed successfully! ðŸŽ‰'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Cleanup
  cleanup:
    runs-on: ubuntu-latest
    name: Cleanup
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Cleanup old artifacts
      uses: actions/github-script@v6
      with:
        script: |
          const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: context.runId,
          });
          
          for (const artifact of artifacts.data.artifacts) {
            if (artifact.name.includes('temp-') && 
                new Date() - new Date(artifact.created_at) > 24 * 60 * 60 * 1000) {
              await github.rest.actions.deleteArtifact({
                owner: context.repo.owner,
                repo: context.repo.repo,
                artifact_id: artifact.id,
              });
            }
          }

  # Generate Test Report
  test-report:
    runs-on: ubuntu-latest
    name: Generate Test Report
    needs: [test, e2e-tests, performance-tests]
    if: always()
    
    steps:
    - name: Download test artifacts
      uses: actions/download-artifact@v3
      with:
        path: test-results
        
    - name: Generate combined test report
      run: |
        echo "# Test Report for ${{ github.sha }}" > test-report.md
        echo "" >> test-report.md
        echo "## Test Summary" >> test-report.md
        echo "- **Branch:** ${{ github.ref }}" >> test-report.md
        echo "- **Commit:** ${{ github.sha }}" >> test-report.md
        echo "- **Workflow:** ${{ github.run_id }}" >> test-report.md
        echo "- **Date:** $(date)" >> test-report.md
        echo "" >> test-report.md
        
        if [[ "${{ needs.test.result }}" == "success" ]]; then
          echo "âœ… Unit & Integration Tests: PASSED" >> test-report.md
        else
          echo "âŒ Unit & Integration Tests: FAILED" >> test-report.md
        fi
        
        if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
          echo "âœ… End-to-End Tests: PASSED" >> test-report.md
        else
          echo "âŒ End-to-End Tests: FAILED" >> test-report.md
        fi
        
        if [[ "${{ needs.performance-tests.result }}" == "success" ]]; then
          echo "âœ… Performance Tests: PASSED" >> test-report.md
        else
          echo "âš ï¸ Performance Tests: SKIPPED/FAILED" >> test-report.md
        fi
        
    - name: Upload test report
      uses: actions/upload-artifact@v3
      with:
        name: test-report
        path: test-report.md
        retention-days: 30